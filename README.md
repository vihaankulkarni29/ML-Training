# ü§ñ Vihaan's ML Engineering Workspace

> **Mission:** Build production-ready ML projects with world-class data storytelling.

This workspace is designed to accelerate ML project development with standardized templates, reusable utilities, and a focus on **explainability** and **deployment**.

---

## üìÅ Workspace Structure

```
ML/
‚îú‚îÄ‚îÄ projects/               # Individual ML projects live here
‚îÇ   ‚îú‚îÄ‚îÄ project-1/
‚îÇ   ‚îú‚îÄ‚îÄ project-2/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ templates/              # Reusable code templates
‚îú‚îÄ‚îÄ utils/                  # Shared utilities across all projects
‚îÇ   ‚îú‚îÄ‚îÄ visualization_helpers.py    # Plotly visualization templates
‚îÇ   ‚îî‚îÄ‚îÄ model_evaluation.py         # Model evaluation utilities
‚îú‚îÄ‚îÄ create_project.py       # üöÄ Project generator script
‚îî‚îÄ‚îÄ README.md              # You are here
```

---

## üöÄ Quick Start: Create a New Project

Run the project generator to scaffold a production-ready ML project:

```powershell
python create_project.py "Project Name"
```

### What Gets Created:

```
project-name/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Store raw datasets here (gitignored)
‚îÇ   ‚îî‚îÄ‚îÄ processed/          # Cleaned/transformed data
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ 01_eda.ipynb        # Starter EDA notebook with Plotly templates
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py    # Data preprocessing functions
‚îÇ   ‚îú‚îÄ‚îÄ train.py            # Model training utilities
‚îÇ   ‚îî‚îÄ‚îÄ visualization.py    # Project-specific visualizations
‚îú‚îÄ‚îÄ models/                 # Saved models (gitignored)
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ figures/            # Saved Plotly charts
‚îÇ   ‚îî‚îÄ‚îÄ reports/            # Generated reports
‚îú‚îÄ‚îÄ app.py                  # Streamlit deployment template
‚îú‚îÄ‚îÄ requirements.txt        # Dependencies
‚îú‚îÄ‚îÄ .gitignore              # Proper ML gitignore
‚îî‚îÄ‚îÄ README.md               # Portfolio-ready documentation template
```

---

## üéØ Philosophy

### 1. **Code for Production**
- No messy notebooks with 500 lines of code
- Refactor complex logic into `src/` modules
- Use sklearn Pipelines for reproducibility

### 2. **Visualization First**
- Default to **Plotly Express** (interactive > static)
- Every chart must tell a story
- Include titles, axis labels, and hover data

### 3. **Explainability is Mandatory**
- Always explain model predictions (SHAP, feature importance)
- Visualize confusion matrices and error analysis
- No black box models

### 4. **Deployment Mindset**
- Every project gets a `app.py` Streamlit template
- Models saved with `joblib` for easy loading
- README formatted for portfolio/resume

---

## üõ†Ô∏è Shared Utilities

### `utils/visualization_helpers.py`
Pre-built Plotly templates for common charts:
- `create_distribution_plot()` - Histograms with KDE overlays
- `create_correlation_heatmap()` - Interactive correlation matrices
- `create_scatter_with_trend()` - Scatter plots with trendlines
- `create_grouped_bar_chart()` - Grouped bar charts
- `create_time_series_plot()` - Time series with range slider

### `utils/model_evaluation.py`
Comprehensive evaluation functions:
- `evaluate_classifier()` - Confusion matrix, ROC curve, classification report
- `evaluate_regressor()` - R¬≤, RMSE, MAE, residual plots
- `print_evaluation_summary()` - Formatted metric summary

**Usage Example:**
```python
from utils.model_evaluation import evaluate_classifier

results = evaluate_classifier(y_test, y_pred, y_proba)
results['confusion_matrix_fig'].show()
print_evaluation_summary(results)
```

---

## üìã Project Workflow

### Phase 1: Setup
```powershell
python create_project.py "Customer Churn Prediction"
cd projects/customer-churn-prediction
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

### Phase 2: EDA
1. Add dataset to `data/raw/`
2. Open `notebooks/01_eda.ipynb`
3. Use Plotly for all visualizations
4. Check for:
   - Missing values
   - Class imbalance
   - Feature distributions
   - Correlations

### Phase 3: Modeling
1. Create baseline model first (e.g., DummyClassifier)
2. Refactor training code into `src/train.py`
3. Use sklearn Pipelines
4. Track experiments (consider MLflow)

### Phase 4: Evaluation
1. Generate confusion matrix
2. Plot SHAP values
3. Analyze misclassifications
4. Save best model to `models/`

### Phase 5: Deployment
1. Update `app.py` with input fields
2. Test locally: `streamlit run app.py`
3. Deploy to Streamlit Cloud (optional)

### Phase 6: Documentation
1. Fill out `README.md` with:
   - Problem statement
   - Key insights (with screenshots)
   - Model metrics
   - Deployment link
2. Use "Problem ‚Üí Method ‚Üí Insight ‚Üí Impact" structure

---

## üì¶ Standard Dependencies

Every project includes:
- **Data:** `pandas`, `numpy`
- **Visualization:** `plotly`, `kaleido`
- **Modeling:** `scikit-learn`
- **Explainability:** `shap`
- **Deployment:** `streamlit`

Optional (uncomment in `requirements.txt` if needed):
- **Experiment Tracking:** `mlflow`, `wandb`
- **Deep Learning:** `torch`, `tensorflow`

---

## üí° Pro Tips

1. **Run baseline first:** Always compare against a simple model
2. **Plotly over Matplotlib:** Interactive charts reveal more insights
3. **Document as you go:** Fill README during the project, not after
4. **Save figures:** Use `fig.write_html()` to preserve interactivity
5. **Version control:** Commit after each major milestone

---

## üéì Learning Resources

- [Plotly Documentation](https://plotly.com/python/)
- [SHAP Tutorial](https://shap.readthedocs.io/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Scikit-Learn Pipelines](https://scikit-learn.org/stable/modules/compose.html)

---

## üìä Portfolio Goals

- ‚úÖ 1 high-quality project per week
- ‚úÖ Every project deployed with Streamlit
- ‚úÖ README formatted for resume/GitHub
- ‚úÖ Interactive visualizations (no static PNGs)
- ‚úÖ Model explainability included

---

**Built by Vihaan Kulkarni**  
*Senior ML Engineer & Data Storyteller*
